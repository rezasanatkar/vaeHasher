from __future__ import print_function
import tensorflow as tf
import numpy as np
import collections
import time, os
class search(object):
    """This class performs visual search employing binary hash codes of images."""
    def __init__(self, encoder):
        """encoder is the encoder model that must implement compute_codes(images) method where images is an 
        np.array((num_images, image_size))."""
        self.encoder = encoder
    def compute_codes(self, images, binary = False, threshold = 0.0):
        """This method calls the compute_codes of the encoder object to encode the images. If binary == True, the binarized version of 
        codes will be returned with respect to threshold."""
        codes = self.encoder.compute_codes(images)
        if not binary:
            return codes
        return codes > threshold
    def compute_all_codes(self, dataset, binary = False, threshold = 0.0, batch_size = 1000, file_name = None):
        """dataset object is assumed to implement generate_samples(batch_size) which generates np.array((num_images, image_size)).
        Also, the dataset object has the epoch_completed property which will become True if one epoch is completed over all the 
        samples of the dataset. 
        This method calls compute_codes to generate the codes of the images. 
        if file_name != None, the (np.arrag(codes), np.array(labels), np.array(images)) will be dumped in the pickle format in the file. 
        Fianlly, (np.arrag(codes), np.array(labels), np.array(images)) will be returned."""
        #for Mnist, batch_size 1000 is much faster than 100
        images, labels, codes = [], [], []
        while True:
            batch_images, batch_labels = dataset.generate_samples(batch_size)
            if dataset.epoch_completed == True:
                break
            images.append(batch_images)
            labels.append(batch_labels)
            codes.append(self.compute_codes(batch_images, binary = binary, threshold = threshold))
        if file_name:
            with open(file_name, 'w') as f:
                import pickle
                pickle.dump((np.concatenate(codes), np.concatenate(labels), np.concatenate(images)), f)
        return (np.concatenate(codes), np.concatenate(labels), np.concatenate(images))
    def load_codes_from_file(self, file_name):
        """This method loads the computed hash codes saved in the pickle format."""
        with open(file_name, 'r') as f:
            import pickle
            return pickle.load(f)
    def compute_distance_pairwise(self, code_1, code_2, binary = False):
        """This method computes the distance between code_1 and code_2. If binary == False, it computes the Euclidean distance,
        otherwise, it computes the Hamming distance."""
        if not binary:
            return np.sum((code_1 - code_2) ** 2)
        return np.sum(np.logical_xor(code_1, code_2))
    def knn(self, k, points, query_images, binary = False, threshold = 0.0):
        """This method computes the k nearest neighbours in points to each query_image in query_images.
        points is the tuple of already computed (codes, labels, images) of training datapoints.
        Finally, it returns a list of k nearest neighbours of (distance, label) to each query_image."""
        import heapq
        codes, labels, images = points
        t = time.time()
        query_codes = self.compute_codes(query_images, binary = binary, threshold = threshold)
        nlargest = []
        for query_code in query_codes:
            distance = []
            heapq.heapify(distance)
            for i, code in enumerate(codes):
                d = -self.compute_distance_pairwise(query_code, code, binary = binary)
                if len(distance) < k:
                    heapq.heappush(distance, (d, labels[i]))
                elif d > distance[0][0]:
                    heapq.heapreplace(distance, (d, labels[i]))
            nlargest.append(heapq.nlargest(k, distance))
        return nlargest
    def compute_precision(self, query_labels, knns):
        """This method gets query_lables and k nearest neighbours of a set of query images, and compute the precision of returned 
        knn for each query image."""
        precision = []
        for query_label, knn in zip(query_labels, knns):
            num_correct = 0.0
            for _, label in knn:
                if label == query_label:
                    num_correct += 1
            precision.append(num_correct / len(knn))
        return precision
    def compute_overall_precision(self, dataset, points, k, binary = False, threshold = 0.0, batch_size = 1000, num_batches = float('inf')):
        """This method computes the overall precision of the k nearest neighbours the encoder based on the testdata generated by 
        the dataset arguement. 
        datset is the test dataset that is assumed to implement generate_samples method as well as epoch_completed that determnies
        whether one full epoch on the test dataset is completed. 
        If num_batches is not provided, then computing overall precision is done for the whole test data set and if it is provided then, it 
        will be only computed for those batches."""
        precision_per_class = collections.defaultdict(list)
        n = 0
        while True:
            batch_images, batch_labels = dataset.generate_samples(batch_size)
            print("batch num: %d" % n)
            n += 1
            if dataset.epoch_completed == True:
                break
            distance = self.knn(k, points, batch_images, binary = binary, threshold = threshold)
            precisions = self.compute_precision(batch_labels, distance)
            for i, precision in enumerate(precisions):
                precision_per_class[batch_labels[i]].append(precision)
            if n > num_batches:
                break
        for c in precision_per_class:
            precision_per_class[c] = sum(precision_per_class[c]) / len(precision_per_class[c])
        return precision_per_class

##### Gaussian
def vae_gaussian_compute_all_codes(binary = True, path_model = 'models/gaussian/vae/model'):
    from encoder import encoder
    _search = search(encoder(filename_meta_graph = 'models/gaussian/encoder/model', path_model = path_model, 
                             input_name = 'x', output_name = 'encoder_params'))
    if binary:
        file_name = os.path.join(os.path.dirname(path_model), 'codes.binary')
    else:
        file_name = os.path.join(os.path.dirname(path_model), 'codes.real')

    from mnist import mnist
    _mnist = mnist()
    codes, labels, images = _search.compute_all_codes(_mnist.train, binary = binary, file_name = file_name)
def vae_gaussian_overall_precision(path_model = 'models/gaussian/vae/model', num_batches = 10):
    from encoder import encoder
    _search = search(encoder(filename_meta_graph = 'models/gaussian/encoder/model', path_model = path_model, 
                             input_name = 'x', output_name = 'encoder_params'))
    from mnist import mnist
    _mnist = mnist()
    points_binary = _search.load_codes_from_file(os.path.join(os.path.dirname(path_model), 'codes.binary'))
    points_real = _search.load_codes_from_file(os.path.join(os.path.dirname(path_model), 'codes.real'))
    print('binary: ', _search.compute_overall_precision(_mnist.test, points_binary, 100, binary = True, batch_size = 100, 
                                                        num_batches = num_batches))
    _mnist = mnist()
    print('real: ', _search.compute_overall_precision(_mnist.test, points_real, 100, binary = False, batch_size = 100, 
                                                      num_batches = num_batches))
def vae_gaussian_example(binary = True):
    from encoder import encoder
    _search = search(encoder(filename_meta_graph = 'models/gaussian/encoder/model', path_model = 'models/gaussian/vae/model', 
                             input_name = 'x', output_name = 'encoder_params'))

    from mnist import mnist
    _mnist = mnist()
    images, labels = _mnist.train.generate_samples(2)
    codes = _search.compute_codes(images, binary = binary)
    print(codes)
    print(_search.compute_distance_pairwise(codes[0], codes[1], binary = binary))

######## Bernoulli

def vae_bernoulli_compute_all_codes(binary = True, path_model = 'models/bernoulli/vae/model'):
    threshold = 0.5
    from encoder import encoder
    _search = search(encoder(filename_meta_graph = 'models/bernoulli/encoder/model', path_model = path_model, 
                             input_name = 'x', output_name = 'encoder_softmax'))
    if binary:
        file_name = os.path.join(os.path.dirname(path_model), 'codes.binary')
    else:
        file_name = os.path.join(os.path.dirname(path_model), 'codes.real')
    from mnist import mnist
    _mnist = mnist()
    codes, labels, images = _search.compute_all_codes(_mnist.train, binary = binary, file_name = file_name, threshold = threshold)
def vae_bernoulli_overall_precision(path_model = 'models/bernoulli/vae/model', num_batches = 10):
    threshold = 0.5
    from encoder import encoder
    _search = search(encoder(filename_meta_graph = 'models/bernoulli/encoder/model', path_model = path_model, 
                             input_name = 'x', output_name = 'encoder_softmax'))

    from mnist import mnist
    _mnist = mnist()
    points_binary = _search.load_codes_from_file(os.path.join(os.path.dirname(path_model), 'codes.binary'))
    points_real = _search.load_codes_from_file(os.path.join(os.path.dirname(path_model), 'codes.real'))
    print('binary: ', _search.compute_overall_precision(_mnist.test, points_binary, 100, binary = True, batch_size = 100, 
                                                       threshold = threshold, num_batches = num_batches))
    _mnist = mnist()
    print('real: ', _search.compute_overall_precision(_mnist.test, points_real, 100, binary = False, batch_size = 100, threshold = threshold,
                                            num_batches = num_batches))
def vae_bernoulli_example(binary = True):
    from encoder import encoder
    _search = search(encoder(filename_meta_graph = 'models/bernoulli/encoder/model', path_model = 'models/bernoulli/vae/model', 
                             input_name = 'x', output_name = 'encoder_softmax'))

    from mnist import mnist
    _mnist = mnist()
    images, labels = _mnist.train.generate_samples(2)
    codes = _search.compute_codes(images, binary = binary)
    print(codes)
    print(_search.compute_distance_pairwise(codes[0], codes[1], binary = binary, threshold = threshold))

if __name__ == "__main__":
    #vae_gaussina_example(binary = False)
    #vae_gaussian_compute_all_codes(binary = True, path_model = 'models/gaussian/vae/model')
    vae_gaussian_overall_precision(path_model = 'models/gaussian/vae/model')

    #vae_bernoulli_compute_all_codes(binary = False, path_model = 'models/bernoulli/vae_with_KLD/model')
    #vae_bernoulli_overall_precision(path_model = 'models/bernoulli/vae/model')
